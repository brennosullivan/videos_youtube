{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de deep learning baseado na memória de curto prazo (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pandas_datareader import data as pdr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acao = \"MGLU3.SA\"\n",
    "\n",
    "inicio = \"2014-12-31\"\n",
    "final = \"2022-09-15\"\n",
    "\n",
    "dados_acao = pdr.get_data_yahoo(acao, inicio, final)\n",
    "\n",
    "dados_acao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nao pode ser ajustados\n",
    "\n",
    "cotacao = dados_acao['Close'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "cotacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho_dados_treinamento = int(len(cotacao) * 0.8)\n",
    "\n",
    "tamanho_dados_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#escalar os dados entre 0 e 1, para deixar mais fácil o processamento\n",
    "#dados em escala pré definidas são mais fáceis de lidar. \n",
    "\n",
    "escalador = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "dados_entre_0_e_1_treinamento = escalador.fit_transform(cotacao[0: tamanho_dados_treinamento, :])\n",
    "\n",
    "dados_entre_0_e_1_teste = escalador.transform(cotacao[tamanho_dados_treinamento: , :])\n",
    "\n",
    "dados_entre_0_e_1 = list(dados_entre_0_e_1_treinamento.reshape(\n",
    "    len(dados_entre_0_e_1_treinamento))) + list(dados_entre_0_e_1_teste.reshape(len(dados_entre_0_e_1_teste)))\n",
    "                                                \n",
    "\n",
    "dados_entre_0_e_1 = np.array(dados_entre_0_e_1).reshape(len(dados_entre_0_e_1), 1)\n",
    "\n",
    "dados_entre_0_e_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_para_treinamento = dados_entre_0_e_1[0: tamanho_dados_treinamento, :]\n",
    "\n",
    "#dados que serão usados para gerar o resultado\n",
    "treinamento_x = []\n",
    "#cotação que aconteceu de fato\n",
    "treinamento_y = []\n",
    "\n",
    "\n",
    "for i in range(60, len(dados_para_treinamento)):\n",
    "\n",
    "    #60 ultimos dias\n",
    "    treinamento_x.append(dados_para_treinamento[i - 60: i, 0])\n",
    "    #cotacao\n",
    "    treinamento_y.append(dados_para_treinamento[i, 0])\n",
    "\n",
    "    if i <= 61:\n",
    "\n",
    "        print(treinamento_x)\n",
    "        print(treinamento_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando as listas em arrays e dando reshape 3d \n",
    "\n",
    "treinamento_x, treinamento_y = np.array(treinamento_x), np.array(treinamento_y)\n",
    "\n",
    "print(treinamento_x)\n",
    "\n",
    "treinamento_x = treinamento_x.reshape(treinamento_x.shape[0], treinamento_x.shape[1], 1)\n",
    "\n",
    "print(treinamento_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construindo o modelo\n",
    "\n",
    "modelo = Sequential()\n",
    "\n",
    "#vamos criar um modelo com 50 neurônios\n",
    "#return sequences = True pois vamos usar outro LSTM depois.\n",
    "#definir o shape, que no caso são 60 informações para gerar uma.\n",
    "#Adicionar mais neurônios com o dense, 25 e 1\n",
    "#Não se apegue a isso agora, é apenas um arquitetura de deep learning.\n",
    "\n",
    "modelo.add(LSTM(50, return_sequences=True, input_shape = (treinamento_x.shape[1], 1)))\n",
    "modelo.add(LSTM(50, return_sequences=False))\n",
    "modelo.add(Dense(25))\n",
    "modelo.add(Dense(1))\n",
    "\n",
    "treinamento_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copilando o modelo\n",
    "\n",
    "# a função de loss é a forma de medir o erro do modelo, que nesse caso\n",
    "#é o classico erro médio quadrático da que é usado em regressão linear\n",
    "#otimizador e medida de erro\n",
    "\n",
    "modelo.compile(optimizer=\"adam\", loss=\"mean_squared_error\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agora com o modelo copilado e os dados, podemos treinar o modelo\n",
    "#batch size é depois de quantas em quantas amostras o modelo irá otimizar os parâmetros.\n",
    "#epochs é quantas vezes o algoritmo irá rodar os dados treinamento, aprendendo. \n",
    "\n",
    "modelo.fit(treinamento_x, treinamento_y, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar dados de teste\n",
    "\n",
    "dados_teste = dados_entre_0_e_1[tamanho_dados_treinamento - 60:, :]\n",
    "\n",
    "teste_x = []\n",
    "teste_y = cotacao[tamanho_dados_treinamento: , :] \n",
    "\n",
    "for i in range(60, len(dados_teste)):\n",
    "    teste_x.append(dados_teste[i - 60: i, 0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape\n",
    "teste_x = np.array(teste_x)\n",
    "teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pegando predições do modelo\n",
    "\n",
    "predicoes = modelo.predict(teste_x)\n",
    "\n",
    "#tirando a escala dos dados\n",
    "\n",
    "predicoes = escalador.inverse_transform(predicoes)\n",
    "\n",
    "predicoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pegando o erro médio quadrático (RMSE)\n",
    "\n",
    "rmse = np.sqrt(np.mean(predicoes - teste_y) ** 2)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando o grafico do modelo\n",
    "\n",
    "\n",
    "treinamento = dados_acao.iloc[:tamanho_dados_treinamento, :]\n",
    "df_teste = pd.DataFrame({\"Close\": dados_acao['Close'].iloc[tamanho_dados_treinamento:],\n",
    "                        \"predicoes\": predicoes.reshape(len(predicoes))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(16, 8))\n",
    "plt.title('Modelo')\n",
    "plt.xlabel('Data', fontsize = 18)\n",
    "plt.ylabel(\"Preço de fechamento\", fontsize = 18)\n",
    "plt.plot(treinamento['Close'])\n",
    "plt.plot(df_teste[['Close', 'predicoes']])\n",
    "plt.legend(['Treinamento', 'Real', 'Predições'], loc=2, prop={'size': 16})\n",
    "plt.show()\n",
    "\n",
    "#essa queda pegou o modelo despevinido, pois MGLU só subia até então praticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste.sort_index()\n",
    "\n",
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#o preço é legal, mas o importante é acertar pra qual mercado o lado vai. Sera q isso foi feito?\n",
    "\n",
    "#calcular media de acertos e expectativa de lucro\n",
    "\n",
    "df_teste['variacao_percentual_acao'] = df_teste['Close'].pct_change()\n",
    "df_teste['variacao_percentual_modelo'] = df_teste['predicoes'].pct_change()\n",
    "\n",
    "df_teste = df_teste.dropna()\n",
    "\n",
    "df_teste['var_acao_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_acao'] > 0, \n",
    "                                                      True, False)\n",
    "df_teste['var_modelo_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_modelo'] > 0, \n",
    "                                                      True, False)\n",
    "\n",
    "df_teste['acertou_o_lado'] = np.where(df_teste['var_acao_maior_menor_que_zero'] == df_teste['var_modelo_maior_menor_que_zero']\n",
    "                                      , True, False)\n",
    "\n",
    "df_teste['variacao_percentual_acao_abs'] = df_teste['variacao_percentual_acao'].abs()\n",
    "\n",
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertou_lado = df_teste['acertou_o_lado'].sum()/len(df_teste['acertou_o_lado'])\n",
    "errou_lado = 1 - acertou_lado\n",
    "\n",
    "media_lucro = df_teste.groupby('acertou_o_lado')['variacao_percentual_acao_abs'].mean()\n",
    "\n",
    "exp_mat_lucro = acertou_lado * media_lucro[1] - media_lucro[0] * errou_lado\n",
    "\n",
    "ganho_sobre_perda = media_lucro[1]/media_lucro[0]\n",
    "\n",
    "print(media_lucro)\n",
    "print(ganho_sobre_perda)\n",
    "print(acertou_lado)\n",
    "print(exp_mat_lucro * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando um código que você passa 60 dias e ele devolve a cotação\n",
    "#resumindo: vamos descobrir o preço da petrobras de hoje/amanha com esse modelo\n",
    "\n",
    "data_hoje = datetime.now()\n",
    "\n",
    "#se quiser escolher um dia, basta fazer assim\n",
    "\n",
    "#data_hoje = datetime.now() - timedelta(days = 1)\n",
    "\n",
    "if data_hoje.hour > 18:\n",
    "    \n",
    "    final = data_hoje\n",
    "    inicial = datetime.now() - timedelta(days = 252)\n",
    "    \n",
    "else:\n",
    "    final = data_hoje - timedelta(days = 1)\n",
    "    inicial = datetime.now() - timedelta(days = 252)\n",
    "    \n",
    "#nao vai botar outra ação aqui hein kkkkkkkk\n",
    "cotacoes = pdr.get_data_yahoo(acao, inicial, final) \n",
    "ultimos_60_dias = cotacoes['Close'].iloc[-60:].values.reshape(-1, 1)\n",
    "\n",
    "ultimos_60_dias_escalado = escalador.transform(ultimos_60_dias)\n",
    "\n",
    "teste_x = []\n",
    "teste_x.append(ultimos_60_dias_escalado)\n",
    "teste_x = np.array(teste_x)\n",
    "teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)\n",
    "\n",
    "previsao_de_preco = modelo.predict(teste_x)\n",
    "previsao_de_preco = escalador.inverse_transform(previsao_de_preco)\n",
    "\n",
    "print(previsao_de_preco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sugestões:\n",
    "<br>\n",
    "\n",
    "- Melhorar as estatísticas de avaliação (dias seguidos ganhando, max DD, etc)\n",
    "<br>\n",
    "\n",
    "- Rodar pra todas as ações do ibovespa e criar uma expectativa matemática da expectativa matemática. Isso vai deixar o resultado final ainda mais robusto, definando a aloção do $ basedo na liquidez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "60c216e46b94f58a5fde426b81c8807da9e6291eb1596ef61e4d2d1672a8d8af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
